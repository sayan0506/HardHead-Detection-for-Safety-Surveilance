{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Personal Safety Equipment Detection System using YoloV3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMGo/iwyl6eKuA0jJGYgjAB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayan0506/HardHead-Detection-for-Safety-Surveilance-using-YoloV3/blob/main/Personal_Safety_Equipment_Detection_System_using_YoloV3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKDtCB9CQGrF"
      },
      "source": [
        "# **Implement YoloV3 based Safety Equipment Detection using Tensorflow**\n",
        "\n",
        "â€¢ **Task: Build A Personal Safety Equipment Detection System**\n",
        "\n",
        "In this noteboook we will try to build a Helmet Detection system from real time images in contruction sites as a personal safety system. The system should detect either head or helmet independently from the images. YoloV3(You Only Look Once Version 3) is an efficient model which has darknet as it's backbone, will be used here to efficiently and fast detect and process the images/video-frame in real time scenarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkQhIIzvV21Z"
      },
      "source": [
        "## **Install Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FJb7ePmV7Eg"
      },
      "source": [
        "# install tensorflow gpu\n",
        "!pip install tensorflow-gpu==2.4.2\n",
        "\n",
        "# install opencv = 4.1.1.26\n",
        "!pip install opencv-python==4.1.1.26\n",
        "\n",
        "# install lxml(helps to parse xml annotations)\n",
        "!pip install lxml\n",
        "\n",
        "# install tqdm(it helps to visualize the progress bar while iterating a loop)\n",
        "# it adds a smart progress meter in loop execution\n",
        "!pip install tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLeTUdMwPY1B"
      },
      "source": [
        "## **Import Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejSfmNpOtxJ6"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from absl import logging\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import time\n",
        "#hashlib helps to encypt the data so that data does not get changes while parsing\n",
        "import hashlib\n",
        "\n",
        "import lxml.etree # to process xml tree structure in Pascal Voc annot files\n",
        "import tqdm"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoDixLF1Rv1E"
      },
      "source": [
        "## **Mount Drive**\n",
        "\n",
        "Drive mail_id: hazrasayan2020@gmail.com"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nfW1jreQumT",
        "outputId": "c35c6f54-4b73-4173-fb9c-a16ba5d857b4"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS3osD1JTCrO"
      },
      "source": [
        "## **Environment Setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaqzkCgkTHHW"
      },
      "source": [
        "**Improve Reproducibility**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuXx5WnkSqfT"
      },
      "source": [
        "# improve reproducibility and make it more deterministic\n",
        "os.environ['TF_CUDNN_DETEREMINISTIC'] = '1'\n",
        "random.seed(hash('setting random seeds') % 2**32 -1)\n",
        "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
        "tf.random.set_seed(hash('by removing stochasticity')% 2**32 -1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBGJC0TAUVMx"
      },
      "source": [
        "**GPU Utilization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-zVCSF_UFVr",
        "outputId": "3d38d775-2ce6-45b2-86df-fca0a8e8e274"
      },
      "source": [
        "# system setup \n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 1999536518186882625, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14509932544\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 12908933574867067331\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cav5vdo2UuB6",
        "outputId": "9d24332b-ade9-49d3-9d30-5d554ea608f0"
      },
      "source": [
        "# checking GPU utilization\n",
        "device = tf.test.gpu_device_name()\n",
        "if device != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found!')\n",
        "\n",
        "print(f'Found GPU at {device}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLTdfSsBW-AG"
      },
      "source": [
        "## **Dataset Load**\n",
        "\n",
        "Load the HardHat Dataset zip from drive folder\n",
        "\n",
        "zip_path : \"/content/drive/MyDrive/HardHead Dataset/HardHat_Dataset.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3dwZNtBXVQh"
      },
      "source": [
        "**Define unzipping function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUjx_J1yVE27"
      },
      "source": [
        "def unzipping(src, dst):\n",
        "  if not os.path.isdir(dst):\n",
        "    os.mkdir(dst) # unzip path\n",
        "\n",
        "  # unzipping to dst\n",
        "  with zipfile.ZipFile(src, 'r') as zip_ref:\n",
        "    zip_ref.extractall(dst)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl7VbkQ2X9ki"
      },
      "source": [
        "unzip the dataset zip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz8644t7X8VT"
      },
      "source": [
        "zip_path = '/content/drive/MyDrive/HardHead Dataset/HardHat_Dataset.zip'\n",
        "dataset_path = 'Hardhat_dataset'\n",
        "\n",
        "# unzip\n",
        "unzipping(zip_path, dataset_path)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxEXqHI7mHuA"
      },
      "source": [
        "## **Data Preperation**\n",
        "\n",
        "Define class dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wx-CB6ctYb6G",
        "outputId": "f6e9f79c-6414-4c8c-e2c0-54719229dd05"
      },
      "source": [
        "classifiers = ['helmet', 'head']\n",
        "\n",
        "id_list = [i for i in range(len(classifiers))]\n",
        "\n",
        "class_dict = dict(zip(classifiers, id_list))\n",
        "\n",
        "print(f'Class dictionary for hardhead dataset {class_dict}')\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class dictionary for hardhead dataset {'helmet': 0, 'head': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IkQE-pWoWFm"
      },
      "source": [
        "**Write classes.names text file to store the class list**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIUPh_zvoQdh"
      },
      "source": [
        "labels_str = '\\n'.join(sorted(class_dict.keys()))\n",
        "drive_path = '/content/drive/MyDrive/HardHead Dataset/' \n",
        "\n",
        "# class file path(.names is a text file to store the object labels)\n",
        "class_path = '/content/drive/MyDrive/HardHead Dataset/hardhat_classes.names'\n",
        "\n",
        "with open(class_path, 'w') as f:\n",
        " f.write(labels_str)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfriVpyUyGiW"
      },
      "source": [
        "**Write image_names.txt file to store the image names present in the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqswGqqoyDbE",
        "outputId": "acdd8fa1-8778-49b5-93f5-dda60adc8cdd"
      },
      "source": [
        "img_list = os.listdir(os.path.join(unzip_path, 'images'))\n",
        "annot_list = os.listdir(os.path.join(unzip_path, 'annotations'))\n",
        "\n",
        "# verify lenght with annotation lenghts\n",
        "assert len(img_list) == len(annot_list)\n",
        "print(f'Total image samples in the dataset {len(img_list)}')\n",
        "\n",
        "img_file_path = os.path.join(drive_path, 'hardhat_image_names.txt')\n",
        "img_id_list = [id for id,_ in enumerate(img_list)]\n",
        "img_names = [img.split('.')[0] for img in img_list]\n",
        "print(f'Sample image  name: {img_names[0]}')\n",
        "\n",
        "img_dict = dict(zip(img_names, img_id_list))\n",
        "\n",
        "imgs_str = '\\n'.join(sorted(img_dict.keys()))\n",
        "\n",
        "# image names file path\n",
        "with open(img_file_path, 'w') as f:\n",
        " f.write(imgs_str)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total image samples in the dataset 4750\n",
            "Sample image  name: hard_hat_workers1858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdUhxhartMCj"
      },
      "source": [
        "#### **Prepare TfRecords**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnyI-GUitXM1"
      },
      "source": [
        "**Function to build the tf-records from annotaion files and images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXg5FMGatd2Y"
      },
      "source": [
        "def build_example(data_dir, annotation, class_map):\n",
        "    img_path = os.path.join(\n",
        "        data_dir, 'images', annotation['filename'])\n",
        "    img_raw = open(img_path, 'rb').read()\n",
        "    # encrypt images\n",
        "    key = hashlib.sha256(img_raw).hexdigest()\n",
        "\n",
        "    width = int(annotation['size']['width'])\n",
        "    height = int(annotation['size']['height'])\n",
        "\n",
        "    xmin = []\n",
        "    ymin = []\n",
        "    xmax = []\n",
        "    ymax = []\n",
        "    classes = []\n",
        "    classes_text = []\n",
        "    truncated = []\n",
        "    views = []\n",
        "    difficult_obj = []\n",
        "    if 'object' in annotation:\n",
        "        for obj in annotation['object']:\n",
        "            difficult = bool(int(obj['difficult']))\n",
        "            difficult_obj.append(int(difficult))\n",
        "\n",
        "            xmin.append(float(obj['bndbox']['xmin']) / width)\n",
        "            ymin.append(float(obj['bndbox']['ymin']) / height)\n",
        "            xmax.append(float(obj['bndbox']['xmax']) / width)\n",
        "            ymax.append(float(obj['bndbox']['ymax']) / height)\n",
        "            classes_text.append(obj['name'].encode('utf8'))\n",
        "            classes.append(class_map[obj['name']])\n",
        "            truncated.append(int(obj['truncated']))\n",
        "            views.append(obj['pose'].encode('utf8'))\n",
        "\n",
        "    example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
        "        'image/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
        "        'image/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[\n",
        "            annotation['filename'].encode('utf8')])),\n",
        "        'image/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[\n",
        "            annotation['filename'].encode('utf8')])),\n",
        "        'image/key/sha256': tf.train.Feature(bytes_list=tf.train.BytesList(value=[key.encode('utf8')])),\n",
        "        'image/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),\n",
        "        'image/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=['jpeg'.encode('utf8')])),\n",
        "        'image/object/bbox/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=xmin)),\n",
        "        'image/object/bbox/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=xmax)),\n",
        "        'image/object/bbox/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=ymin)),\n",
        "        'image/object/bbox/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=ymax)),\n",
        "        'image/object/class/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=classes_text)),\n",
        "        'image/object/class/label': tf.train.Feature(int64_list=tf.train.Int64List(value=classes)),\n",
        "        'image/object/difficult': tf.train.Feature(int64_list=tf.train.Int64List(value=difficult_obj)),\n",
        "        'image/object/truncated': tf.train.Feature(int64_list=tf.train.Int64List(value=truncated)),\n",
        "        'image/object/view': tf.train.Feature(bytes_list=tf.train.BytesList(value=views)),\n",
        "    }))\n",
        "    return example\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cci6-s8vIL0"
      },
      "source": [
        "**Define function to parse xml annotations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LETyG5_qvPS5"
      },
      "source": [
        "def parse_xml(xml):\n",
        "    if not len(xml):\n",
        "        return {xml.tag: xml.text}\n",
        "    result = {}\n",
        "    for child in xml:\n",
        "        child_result = parse_xml(child)\n",
        "        if child.tag != 'object':\n",
        "            result[child.tag] = child_result[child.tag]\n",
        "        else:\n",
        "            if child.tag not in result:\n",
        "                result[child.tag] = []\n",
        "            result[child.tag].append(child_result[child.tag])\n",
        "    return {xml.tag: result}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_iRdVJhweAB"
      },
      "source": [
        "**Class map**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u468xmlUonKf",
        "outputId": "14810ed8-aae3-48e7-9b75-c8f05e399986"
      },
      "source": [
        "class_map = {name: idx for idx, name in enumerate(\n",
        "    open(class_path).read().splitlines())}\n",
        "print(f'Class mapping loaded: {class_map}')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class mapping loaded: {'head': 0, 'helmet': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIpxK_0gwgLx"
      },
      "source": [
        "**Fetch image list**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek068M_tp5fO",
        "outputId": "fb2d5783-6d19-4f08-a1a4-e2a469936b68"
      },
      "source": [
        "image_list = open(img_file_path).read().splitlines()\n",
        "print(\"Image list loaded: \", len(image_list))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image list loaded:  4750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwARt9py31a3"
      },
      "source": [
        "**Create Tfrecords**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEh6m3PF3Pzw",
        "outputId": "31c3bbcd-c84f-42f7-8c9c-f447c530d494"
      },
      "source": [
        "# define tfrecords metadata\n",
        "train_record = os.path.join(drive_path, 'hardhat_train.tfrecord')\n",
        "\n",
        "# writer object\n",
        "writer = tf.io.TFRecordWriter(train_record)\n",
        "\n",
        "for name in tqdm.tqdm(image_list[:3]):\n",
        "  annotation_xml = os.path.join(dataset_path, 'annotations', name + '.xml')\n",
        "  # read annotation files\n",
        "  annotation_xml = lxml.etree.fromstring(open(annotation_xml).read())\n",
        "  # parse the annotation xml\n",
        "  annotation = parse_xml(annotation_xml)['annotation']\n",
        "  # build tfrecords\n",
        "  tf_example = build_example(dataset_path, annotation, class_map)\n",
        "  writer.write(tf_example.SerializeToString())\n",
        "\n",
        "writer.close()\n",
        "print('\\nTfrecord conversion is Done!')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 316.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Tfrecord conversion is Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDM8i53P7yrW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}